spring.application.name=TEDTalkRAGAssistant

server.port=${PORT:8080}

# Chunking Configuration
tedtalk.batch.size=100
tedtalk.chunk.size=1024
tedtalk.chunk.overlap=205
tedtalk.top.k=5

# Set to true for AI-based chunking (slower, smarter)
# Set to false for simple text chunking (faster, recommended for bog datasets)
tedtalk.use.ai.chunking=false

# OpenAI Configuration (LLMod.ai proxy)
spring.ai.openai.api-key=sk-gn6ItTVdbwHbFB783OPJnA
spring.ai.openai.base-url=https://api.llmod.ai
spring.ai.openai.chat.options.model=RPRTHPB-gpt-5-mini

# Embedding configuration - BOTH are needed
spring.ai.openai.embedding.options.model=RPRTHPB-text-embedding-3-small
spring.ai.openai.embedding-model=RPRTHPB-text-embedding-3-small

# Pinecone Configuration
spring.ai.vectorstore.pinecone.api-key=pcsk_3p8qLF_HdZkwvPvBoKvu5Jxhfi1Hfhy6V6R2dwRtcnu9W9XFsQLHNH6XzVbmVvNdpAJjTN
spring.ai.vectorstore.pinecone.index-name=ted-talk-rag-assistant

# File path
file.tedtalk.csv=C:\\Users\\yosra\\ted_talks_en.csv